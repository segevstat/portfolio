{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d779d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"shubhambathwal/flight-price-prediction\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eacd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\segev\\code_notebooks\\Clean_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3055fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.price*0.04).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "123071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57593ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f288032",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.airline.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaef26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(data.flight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.source_city.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5856520",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.departure_time.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc211161",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.arrival_time.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.stops.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.destination_city.value_counts())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76257adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install contextily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "\n",
    "df = pd.DataFrame({'destination_city': ['Mumbai', 'Delhi', 'Bangalore', 'Kolkata', 'Hyderabad', 'Chennai']})\n",
    "\n",
    "df = df.drop_duplicates(subset=['destination_city'])\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\", timeout=10)  # Increased timeout\n",
    "\n",
    "def get_coordinates_and_state(city):\n",
    "    retries = 5\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            location = geolocator.geocode(city, timeout=10)  # Increase timeout\n",
    "            if location:\n",
    "                address = location.raw.get('address', {})\n",
    "                state = address.get('state')  # Get the state name\n",
    "                return location.latitude, location.longitude, state\n",
    "        except (GeocoderTimedOut, GeocoderServiceError):\n",
    "            print(f\"Retry {i+1}/{retries} for {city}...\")\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "    return None, None, None  # Return None if all retries fail\n",
    "\n",
    "# Apply geocoding to get coordinates and state\n",
    "df['latitude'], df['longitude'], df['state'] = zip(*df['destination_city'].apply(get_coordinates_and_state))\n",
    "\n",
    "# Drop rows where geocoding failed\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(df['longitude'], df['latitude'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "gdf.plot(ax=ax, color='red', alpha=0.6, edgecolor='k', markersize=10)  # Fixed size for markers\n",
    "\n",
    "# Add OpenStreetMap basemap\n",
    "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "# Annotate city names and states\n",
    "for x, y, label, state in zip(gdf.geometry.x, gdf.geometry.y, gdf['destination_city'], gdf['state']):\n",
    "    ax.text(x, y, f\"{label}, {state}\", fontsize=9, ha='right', color='black', weight='bold')\n",
    "\n",
    "# Remove axis for better visualization\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data['duration'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data['days_left'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data['price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(data['price'])), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79139ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fb525",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8178a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a03e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['Unnamed: 0', 'flight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf464295",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258983b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9830434",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(raw['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['class']=raw['class'].replace({'Business':1,\n",
    "                                   'Economy':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3178f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(raw['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55686ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.stops=pd.factorize(raw.stops)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12539fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(raw.stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae829888",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=raw.join(pd.get_dummies(raw.airline, prefix='airline')).drop(columns=['airline'])\n",
    "\n",
    "raw=raw.join(pd.get_dummies(raw.source_city, prefix='source_city')).drop(columns=['source_city'])\n",
    "\n",
    "raw=raw.join(pd.get_dummies(raw.destination_city, prefix='destination_city')).drop(columns=['destination_city'])\n",
    "\n",
    "raw=raw.join(pd.get_dummies(raw.arrival_time, prefix='arrival_time')).drop(columns=['arrival_time'])\n",
    "\n",
    "raw=raw.join(pd.get_dummies(raw.departure_time, prefix='departure_time')).drop(columns=['departure_time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d77d8",
   "metadata": {},
   "source": [
    "# Train regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630121b",
   "metadata": {},
   "source": [
    "**RandomForestRegressor is a supervised machine learning algorithm used for predicting continuous numerical values by averaging the outputs of multiple decision trees.**\n",
    "\n",
    "**Each tree is trained on a random subset of the data and features—a process known as bagging—which introduces diversity and reduces overfitting. The final prediction is obtained by aggregating the individual predictions from all trees, typically through averaging, resulting in improved accuracy and robustness.**\n",
    "\n",
    "**This ensemble approach allows RandomForestRegressor to capture complex, non-linear relationships in data without requiring extensive preprocessing or feature scaling. It is widely used in various applications, including stock price forecasting, real estate valuation, and time series prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282696c",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=X1MRbEnEq2s&ab_channel=SuperDataScience  V "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422201c",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=YUsx5ZNlYWc&ab_channel=Ryan%26MattDataScience  X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw.drop(columns='price')\n",
    "\n",
    "y= raw.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dde881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test , y_train , y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587fd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg= RandomForestRegressor(n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a2dcb",
   "metadata": {},
   "source": [
    "​The reg.score(X, y) method in RandomForestRegressor computes the R² score (coefficient of determination), indicating how well the model's predictions match the actual target values. An R² of 1.0 signifies perfect predictions, 0.0 means the model performs no better than predicting the mean of the target values, and negative values indicate worse performance than this baseline. This metric provides a quick assessment of model performance, but for a comprehensive evaluation, consider additional metrics like Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d59c7c",
   "metadata": {},
   "source": [
    "An R² score of 0.98527 from reg.score(X_test, y_test) indicates that your RandomForestRegressor model explains approximately 98.5% of the variance in the test data. This suggests a strong fit between the model's predictions and the actual target values.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ea731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c5f8e",
   "metadata": {},
   "source": [
    "The from sklearn.metrics import * statement imports all available functions and classes from the sklearn.metrics module, which provides a comprehensive suite of tools for evaluating machine learning models. These tools include:​\n",
    "\n",
    "Classification Metrics: Functions like accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, and confusion_matrix are used to assess the performance of classification models.​\n",
    "\n",
    "Regression Metrics: Functions such as mean_squared_error, mean_absolute_error, r2_score, and explained_variance_score help evaluate regression models.​\n",
    "\n",
    "Clustering Metrics: Metrics like adjusted_rand_score, normalized_mutual_info_score, and silhouette_score are used to assess clustering algorithms.​\n",
    "\n",
    "Pairwise Metrics: Functions like pairwise_distances and pairwise_kernels compute distances or similarities between pairs of samples.​\n",
    "\n",
    "Utility Functions: Tools such as make_scorer and get_scorer assist in creating custom scoring functions and retrieving predefined scorers.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a090ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825690f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R2: {r2_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(f\"R-MSE: {math.sqrt(mean_squared_error(y_test, y_pred)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1560fb",
   "metadata": {},
   "source": [
    "The model demonstrates high predictive accuracy, as evidenced by the R² value close to 1. \n",
    "\n",
    "The MAE and RMSE values suggest that, on average, predictions are within a reasonable range of the actual prices.\n",
    "\n",
    "However, the relatively higher RMSE compared to MAE indicates the presence of some larger errors, which could be due to outliers or specific instances where the model's predictions deviate more significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted Flight Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual (Actual - Predicted)\", fontsize=14)\n",
    "plt.title(\"Residual Plot: Predicted vs. Residuals\", fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f1527",
   "metadata": {},
   "source": [
    "Centered residuals: The residuals are generally centered around the 0 line, which is what we expect in a good model.\n",
    "\n",
    "No clear linear pattern: That's a sign your model isn't systematically under- or over-predicting across all price ranges.\n",
    "\n",
    "Densely packed residuals: Many points are close to the zero line, indicating overall strong performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12582f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "print(colored(\"Meta data regarding the predicted value:\", color=\"cyan\", attrs=[\"bold\"]))\n",
    "\n",
    "pd.DataFrame(raw.price.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels = [f\"({np.array(y_test)[i]:.2f}, {np.array(y_pred)[i]:.2f})\" for i in range(len(y_test))]\n",
    "\n",
    "np.random.seed(42) \n",
    "indices_to_label = np.random.choice(len(y_test), size=5, replace=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(np.array(y_test), y_pred, s=100)\n",
    "\n",
    "plt.xlabel(\"Actual flight price\", fontsize=14)\n",
    "plt.ylabel(\"Predicted flight price\", fontsize=14)\n",
    "plt.title(\"Actual vs Predicted Flight Prices\", fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "for i in indices_to_label:\n",
    "    plt.text(np.array(y_test)[i], np.array(y_pred)[i], labels[i],\n",
    "             fontsize=10, ha='right', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ac3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = reg.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "feat_imp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(feat_imp_df[\"Feature\"].head(5),\n",
    "                feat_imp_df[\"Importance\"].head(5),\n",
    "                color='skyblue')\n",
    "\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.title(\"Feature Importances from RandomForestRegressor\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.grid(True, linestyle=\"--\", alpha=0.9)\n",
    "\n",
    "# Add value labels next to bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001,              \n",
    "             bar.get_y() + bar.get_height() / 2,\n",
    "             f\"{width:.3f}\",         \n",
    "             va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754faffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = feat_imp_df[\"Feature\"].head(5)\n",
    "\n",
    "\n",
    "print(\"\\nTop 5 Feature Summary:\\n\")\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Feature\": top_features,\n",
    "    \"Min\": X_train[top_features].min().values,\n",
    "    \"Max\": X_train[top_features].max().values,\n",
    "    \"Unique Values\": X_train[top_features].nunique().values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10_p=X_train.shape[0]*0.25\n",
    "\n",
    "sample_10_p=round(sample_10_p, 0)\n",
    "\n",
    "sample_10_p = int(sample_10_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffff2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from scipy.stats  import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0202d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50],         # Lower number of trees\n",
    "    'max_depth': [10],            # Only one depth\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    reg,\n",
    "    param_grid,\n",
    "    cv=2,            # Only 2-fold CV\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train[top_features][:sample_10_p], y_train[:sample_10_p])\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "\n",
    "best_regressor= grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddab09",
   "metadata": {},
   "source": [
    "Sure! Here's a clear explanation of what the code does, in words only:\n",
    "\n",
    "This script performs a quick hyperparameter tuning of a `RandomForestRegressor` model using only the top 5 most important features. \n",
    "\n",
    "It sets up a simple grid of parameters with minimal options to reduce computation time. The tuning is done using `GridSearchCV` with 2-fold cross-validation and only 10% of the training data. After fitting the model on the selected features and data subset, \n",
    "\n",
    "it retrieves the best-performing estimator from the grid search. This process helps in efficiently finding a decent model without consuming too many resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0908d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0685b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aecc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor.score(X_test[top_features][:sample_10_p], y_test[:sample_10_p])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= best_regressor.predict(X_test[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aee722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R2: {r2_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(f\"R-MSE: {math.sqrt(mean_squared_error(y_test, y_pred)):.3f}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x=raw.price)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(raw.price)\n",
    "outliers = raw[abs(z_scores) > 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=residuals)\n",
    "plt.title(\"Outliers in Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08731b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y_test = np.array(y_test[:sample_10_p])\n",
    "sample_y_pred = np.array(y_pred[:sample_10_p])\n",
    "\n",
    "labels = [f\"({sample_y_test[i]:.2f}, {sample_y_pred[i]:.2f})\" for i in range(sample_10_p)]\n",
    "    \n",
    "np.random.seed(42)\n",
    "indices_to_label = np.random.choice(sample_10_p, size=5, replace=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(sample_y_test, sample_y_pred, s=100)\n",
    "\n",
    "plt.xlabel(\"Actual flight price\", fontsize=14)\n",
    "plt.ylabel(\"Predicted flight price\", fontsize=14)\n",
    "plt.title(\"Actual vs Predicted Flight Prices\", fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "for i in indices_to_label:\n",
    "    plt.text(sample_y_test[i], sample_y_pred[i], labels[i], fontsize=10, ha='right', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume y_train is a Pandas Series\n",
    "Q1 = y_train.quantile(0.25)\n",
    "Q3 = y_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter indices where target is within bounds\n",
    "mask = (y_train >= lower_bound) & (y_train <= upper_bound)\n",
    "\n",
    "# Apply mask to X_train and y_train\n",
    "X_train_clean = X_train[top_features].iloc[:sample_10_p][mask]\n",
    "y_train_clean = y_train.iloc[:sample_10_p][mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e783a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    reg,\n",
    "    param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "best_regressor = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = best_regressor.predict(X_test[top_features])\n",
    "\n",
    "# Evaluate\n",
    "print(f\"R2: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "print(f\"R-MSE: {math.sqrt(mean_squared_error(y_test, y_pred)):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_y_test = np.array(y_test[:sample_10_p])\n",
    "sample_y_pred = np.array(y_pred[:sample_10_p])\n",
    "\n",
    "labels = [f\"({sample_y_test[i]:.2f}, {sample_y_pred[i]:.2f})\" for i in range(sample_10_p)]\n",
    "\n",
    "np.random.seed(42)\n",
    "indices_to_label = np.random.choice(sample_10_p, size=5, replace=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(sample_y_test, sample_y_pred, s=100, alpha=0.6, edgecolor='k')\n",
    "\n",
    "plt.xlabel(\"Actual Flight Price\", fontsize=14)\n",
    "plt.ylabel(\"Predicted Flight Price\", fontsize=14)\n",
    "plt.title(\"Actual vs Predicted Flight Prices\", fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "for i in indices_to_label:\n",
    "    plt.text(sample_y_test[i], sample_y_pred[i], labels[i],\n",
    "             fontsize=10, ha='right', va='bottom', color='darkblue')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
